---
layout: post
title: On 2019 Jun 17 research
---


* ### It's the matter of approachableness


https://arxiv.org/pdf/1906.05833.pdf




## Qurstion : 



can we build a symbolic model as it maximizes the throughput of interpretation between humans and machines?




# Ontology1 :



Princilal as mediocracy for Humans and machines to deliver contexts .

1: Human Readability is cut.

2: processed input shall be performed as humans expect to be.

 
3: scope of the ontology is to minimize the loss of discrephancy of understanding the interpretation between humans and machines.

If we take loss function, it would require attributes of polynomial time, mathematical axons(checl Godel's theorem), 


4: Humans could have hard time to produce semantical meaning to that medium.




4: Expressive medium won't be limited to clearly defined symbol. clear pattern is not in the scope.



5: Let's start off by what's not indeed the unnecessary.

Counting as probably neccessary 





# Ontology 2:


can we first define meaning property of ontologic message given by the machine A, as it signifies the context already, and proceed to attempt to decode it with hardships.








## Approach ;


1.1 = engine 
1.2 = medium representation 
1.3 = binary input of data


 1.3 ->[[1.2.1] 1.1] -> [1.2.2]

purpose to find the patterns of 1.2.2 to be corresponding to 1.1




## Approach 2; 
can we first define meaning property of ontologic message given by the machine A, as it signifies the context already, and proceed to attempt to decode it with hardships.




1.1 = engine
1.2 = medium represntation 
1.3 = human interpretation


1.1 -> [1.2] -> 1.3

purpose to fine the pattern of 1.2 as interpretable with 1.3






## Challenges:


Let's start off by solving small units to generalize as representation.



: Tree straucture -> Is it representable With medium


We could observe tree as the culation of point and arrow.




================================================




Modeling: the Engine 




counter intuitive 



Idea: model m -> can appear to be structural patterns. but at its core it's not.


Idea: DnA like stracture.





Idea: A machine that processes to be ready to be labeled.
	if machine knowingly processes and its exsistance, unified labeled to be scoped would be the way to be examined as close as to the mental process. 

	can we build a thing which processes the representation of logic and mathematics in polynomial time.
	It won't need to define the ruleset of common rules to kick off its representation. 
	It indeed requires assertation by humans to understand labels.




	cellar automation 


	patterns to be labeled, making ruleset of things in mathematical logics to be updated at core.

	Communivative cellar automaton theory as it's unified principal. 



	let them solve simple problem such as  1 = 1.

	if so, the automaton is expected to understand what it means to understand.

	Axom: we need storage to capture the pattern which represents the nortation of understandingness. 






We can see the pattern emerge.
Consistancy is the key.

can we counter regulate as we would like.


















